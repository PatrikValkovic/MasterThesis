@article{CIRESAN2012333,
title = {Multi-column deep neural network for traffic sign classification},
journal = {Neural Networks},
volume = {32},
pages = {333-338},
year = {2012},
note = {Selected Papers from {IJCNN} 2011},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2012.02.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608012000524},
author = {Dan Cireşan and Ueli Meier and Jonathan Masci and Jürgen Schmidhuber},
keywords = {Deep neural networks, Image classification, Traffic signs, Image preprocessing},
abstract = {We describe the approach that won the final phase of the German traffic sign recognition benchmark. Our method is the only one that achieved a better-than-human recognition rate of 99.46%. We use a fast, fully parameterizable GPU implementation of a Deep Neural Network (DNN) that does not require careful design of pre-wired feature extractors, which are rather learned in a supervised way. Combining various DNNs trained on differently preprocessed data into a Multi-Column DNN (MCDNN) further boosts recognition performance, making the system insensitive also to variations in contrast and illumination.}
}

@article{ChecksDocumentRecognition,
author = {Lecun, Yann and Bottou, Leon and Bengio, Y. and Haffner, Patrick},
year = {1998},
month = {12},
pages = {2278 - 2324},
title = {Gradient-Based Learning Applied to Document Recognition},
volume = {86},
journal = {Proceedings of the {IEEE}},
doi = {10.1109/5.726791}
}

@article{HECK2000181,
title = {Robustness to telephone handset distortion in speaker recognition by discriminative feature design},
journal = {Speech Communication},
volume = {31},
number = {2},
pages = {181-192},
year = {2000},
issn = {0167-6393},
doi = {https://doi.org/10.1016/S0167-6393(99)00077-1},
url = {https://www.sciencedirect.com/science/article/pii/S0167639399000771},
author = {Larry P. Heck and Yochai Konig and M.Kemal Sönmez and Mitch Weintraub},
keywords = {Speaker recognition, Speaker verification, Speaker identification, Channel compensation, Channel robustness, Telephone handset distortion, Feature extraction, Neural network, Discriminative design},
abstract = {A method is described for designing speaker recognition features that are robust to telephone handset distortion. The approach transforms features such as mel-cepstral features, log spectrum, and prosody-based features with a non-linear artificial neural network. The neural network is discriminatively trained to maximize speaker recognition performance specifically in the setting of telephone handset mismatch between training and testing. The algorithm requires neither stereo recordings of speech during training nor manual labeling of handset types either in training or testing. Results on the 1998 National Institute of Standards and Technology (NIST) Speaker Recognition Evaluation corpus show relative improvements as high as 28% for the new multilayered perceptron (MLP)-based features as compared to a standard mel-cepstral feature set with cepstral mean subtraction (CMS) and handset-dependent normalizing impostor models.
Zusammenfassung
Der Artikel beschreibt eine Methode zur Bestimmung von Merkmalen zur Sprechererkennung, die robust gegen Verzerrung durch den Telephonhörer sind. In unserem Verfahren werden die Merkmale, wie z.B. Mel-Cepstrum, logarithmisches Spektrum, oder prosodische Merkmale, durch ein nicht-lineares künstliches neuronales Netz transformiert. Das neuronale Netz wird diskriminativ darauf trainiert, die Sprechererkennungsrate bei unterschiedlichen Telephonhörern im Training und Test zu maximieren. Der Algorithmus braucht weder Stereo-Sprachaufzeichnungen im Training, noch bedarf er manueller Feststellung des Hörertyps im Training oder Test. Die Ergebnisse auf dem 1998 NIST Sprechererkennungskorpus zeigen eine relative Verbesserung von bis zu 28% durch die neuen neuronalen-Netz-Merkale, verglichen mit gewöhnlichen Mel-Cepstrum-Merkmalen, Subtraktion der Cepstrum-Mittelwerte und hörerspezifischen normalisierenden Impostor-Modellen.
Résumé
Une méthode est décrite pour l'extraction de vecteurs de caractéristiques robustes aux distortions provenant du type de téléphone utilisé dans des applications de reconnaissance du locuteur. La technique transforme les vecteurs de caractéristiques tels que le Mel-cepstre, le log-spectre et les caractéristiques basées sur la prosodie, à l'aide de réseau de neurones non-linéaire. Le réseau de neurones est entraı&#x0302;né de manière discriminante pour maximiser la performance du système de reconnaissance du locuteur, spécifiquement dans des conditions où des types de téléphone différents sont utilisés lors de l'entraı&#x0302;nement et de la vérification. L'algorithme ne requiert, ni enregistrement stéréo de la session d'entraı&#x0302;nement, ni étiquettage manuel des types de téléphone utilisés à l'entraı&#x0302;nement et à la vérification. Les résultats sur le corpus 1998 NIST Speaker Recognition Evaluation montrent une amélioration relative atteignant 28% avec les nouvelles caractéristiques basées sur le réseau de neurones. Le système de référence utilise des vecteurs de caractéristiques basés le MEL-cepstre avec soustraction du cepstre moyen ainsi que des modèles d'imposteurs dépendant du type de téléphone.}
}

@misc{pham2021meta,
      title={Meta Pseudo Labels}, 
      author={Hieu Pham and Zihang Dai and Qizhe Xie and Minh-Thang Luong and Quoc V. Le},
      year={2021},
      eprint={2003.10580},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inbook{ZawadzkaGosk2019,
author = {Zawadzka-Gosk, Emilia and Wołk, Krzysztof and Czarnowski, Wojciech},
year = {2019},
month = {04},
pages = {946-957},
title = {Deep Learning in State-of-the-Art Image Classification Exceeding 99\% Accuracy},
isbn = {978-3-030-16180-4},
doi = {10.1007/978-3-030-16181-1_89},
publisher = {Springer International Publishing},
}

@misc{ghiasi2020simple,
      title={Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation}, 
      author={Golnaz Ghiasi and Yin Cui and Aravind Srinivas and Rui Qian and Tsung-Yi Lin and Ekin D. Cubuk and Quoc V. Le and Barret Zoph},
      year={2020},
      eprint={2012.07177},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{lehner2019patch,
      title={Patch Refinement -- Localized {3D} Object Detection}, 
      author={Johannes Lehner and Andreas Mitterecker and Thomas Adler and Markus Hofmarcher and Bernhard Nessler and Sepp Hochreiter},
      year={2019},
      eprint={1910.04093},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{gpt3,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zhang2020pushing,
      title={Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition}, 
      author={Yu Zhang and James Qin and Daniel S. Park and Wei Han and Chung-Cheng Chiu and Ruoming Pang and Quoc V. Le and Yonghui Wu},
      year={2020},
      eprint={2010.10504},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@misc{yamada2020luke,
      title={{LUKE}: Deep Contextualized Entity Representations with Entity-aware Self-attention}, 
      author={Ikuya Yamada and Akari Asai and Hiroyuki Shindo and Hideaki Takeda and Yuji Matsumoto},
      year={2020},
      eprint={2010.01057},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lu2020layered,
      title={Layered Neural Rendering for Retiming People in Video}, 
      author={Erika Lu and Forrester Cole and Tali Dekel and Weidi Xie and Andrew Zisserman and David Salesin and William T. Freeman and Michael Rubinstein},
      year={2020},
      eprint={2009.07833},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{StateOfTheArtImageSythesis,
author = {Wang, Lei and Chen, Wei and Yang, Wenjia and Bi, Fangming and Yu, Fei},
year = {2020},
month = {03},
pages = {1-1},
title = {A State-of-the-Art Review on Image Synthesis With Generative Adversarial Networks},
volume = {PP},
journal = {{IEEE} Access},
doi = {10.1109/ACCESS.2020.2982224}
}

@misc{esser2020taming,
      title={Taming Transformers for High-Resolution Image Synthesis},
      author={Patrick Esser and Robin Rombach and Björn Ommer},
      year={2020},
      eprint={2012.09841},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{Sun_2020,
   title={Learned Image Downscaling for Upscaling Using Content Adaptive Resampler},
   volume={29},
   ISSN={1941-0042},
   url={http://dx.doi.org/10.1109/TIP.2020.2970248},
   DOI={10.1109/tip.2020.2970248},
   journal={IEEE Transactions on Image Processing},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Sun, Wanjie and Chen, Zhenzhong},
   year={2020},
   pages={4027–4040}
}

@article{Chadha_2020,
   title={{iSeeBetter}: Spatio-temporal video super-resolution using recurrent generative back-projection networks},
   volume={6},
   ISSN={2096-0662},
   url={http://dx.doi.org/10.1007/s41095-020-0175-7},
   DOI={10.1007/s41095-020-0175-7},
   number={3},
   journal={Computational Visual Media},
   publisher={Springer Science and Business Media LLC},
   author={Chadha, Aman and Britto, John and Roja, M. Mani},
   year={2020},
   month={Jul},
   pages={307–317}
}

@misc{dalle,
      title={Zero-Shot Text-to-Image Generation}, 
      author={Aditya Ramesh and Mikhail Pavlov and Gabriel Goh and Scott Gray and Chelsea Voss and Alec Radford and Mark Chen and Ilya Sutskever},
      year={2021},
      eprint={2102.12092},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{malmi2019encode,
      title={Encode, Tag, Realize: High-Precision Text Editing}, 
      author={Eric Malmi and Sebastian Krause and Sascha Rothe and Daniil Mirylenka and Aliaksei Severyn},
      year={2019},
      eprint={1909.01187},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{Kim_2019,
   title={Deep Fluids: A Generative Network for Parameterized Fluid Simulations},
   volume={38},
   ISSN={1467-8659},
   url={http://dx.doi.org/10.1111/cgf.13619},
   DOI={10.1111/cgf.13619},
   number={2},
   journal={Computer Graphics Forum},
   publisher={Wiley},
   author={Kim, Byungsoo and Azevedo, Vinicius C. and Thuerey, Nils and Kim, Theodore and Gross, Markus and Solenthaler, Barbara},
   year={2019},
   month={May},
   pages={59–70}
}

@misc{um2018liquid,
      title={Liquid Splash Modeling with Neural Networks}, 
      author={Kiwon Um and Xiangyu Hu and Nils Thuerey},
      year={2018},
      eprint={1704.04456},
      archivePrefix={arXiv},
      primaryClass={cs.GR}
}

@misc{lee2019efficient,
      title={Efficient Cloth Simulation using Miniature Cloth and Upscaling Deep Neural Networks}, 
      author={Tae Min Lee and Young Jin Oh and In-Kwon Lee},
      year={2019},
      eprint={1907.03953},
      archivePrefix={arXiv},
      primaryClass={cs.GR}
}

@article {SRBO20,
	author  = {Sánchez-Banderas, Rosa M. and Rodríguez, Alejandro and Barreiro, Héctor and Otaduy, Miguel A.},
	title   = {{Robust Eulerian-on-Lagrangian Rods}},
	number  = "4",
	volume  = "39",
	journal = {{ACM} Transactions on Graphics (Proc. of {ACM} {SIGGRAPH})},
	year    = {2020}
}

@inproceedings{PhysicsSimulation,
author = {Holden, Daniel and Duong, Bang Chi and Datta, Sayantan and Nowrouzezahrai, Derek},
title = {Subspace Neural Physics: Fast Data-Driven Interactive Simulation},
year = {2019},
isbn = {9781450366779},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3309486.3340245},
doi = {10.1145/3309486.3340245},
abstract = {Data-driven methods for physical simulation are an attractive option for interactive applications due to their ability to trade precomputation and memory footprint in exchange for improved runtime performance. Yet, existing data-driven methods fall short of the extreme memory and performance constraints imposed by modern interactive applications like AAA games and virtual reality. Here, performance budgets for physics simulation range from tens to hundreds of micro-seconds per frame, per object. We present a data-driven physical simulation method that meets these constraints. Our method combines subspace simulation techniques with machine learning which, when coupled, enables a very efficient subspace-only physics simulation that supports interactions with external objects - a longstanding challenge for existing subspace techniques. We also present an interpretation of our method as a special case of subspace Verlet integration, where we apply machine learning to efficiently approximate the physical forces of the system directly in the subspace. We propose several practical solutions required to make effective use of such a model, including a novel training methodology required for prediction stability, and a GPU-friendly subspace decompression algorithm to accelerate rendering.},
booktitle = {Proceedings of the 18th Annual ACM SIGGRAPH/Eurographics Symposium on Computer Animation},
articleno = {6},
numpages = {12},
keywords = {collision detection, machine learning, neural networks, cloth simulation, data-driven simulation, model reduction},
location = {Los Angeles, California},
series = {SCA '19}
}

@misc{sanchezgonzalez2020learning,
      title={Learning to Simulate Complex Physics with Graph Networks}, 
      author={Alvaro Sanchez-Gonzalez and Jonathan Godwin and Tobias Pfaff and Rex Ying and Jure Leskovec and Peter W. Battaglia},
      year={2020},
      eprint={2002.09405},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{PhysicsBasedCharaterSImulation,
author = {Bergamin, Kevin and Clavet, Simon and Holden, Daniel and Forbes, James Richard},
title = {{DReCon}: Data-Driven Responsive Control of Physics-Based Characters},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3355089.3356536},
doi = {10.1145/3355089.3356536},
abstract = {Interactive control of self-balancing, physically simulated humanoids is a long standing problem in the field of real-time character animation. While physical simulation guarantees realistic interactions in the virtual world, simulated characters can appear unnatural if they perform unusual movements in order to maintain balance. Therefore, obtaining a high level of responsiveness to user control, runtime performance, and diversity has often been overlooked in exchange for motion quality. Recent work in the field of deep reinforcement learning has shown that training physically simulated characters to follow motion capture clips can yield high quality tracking results. We propose a two-step approach for building responsive simulated character controllers from unstructured motion capture data. First, meaningful features from the data such as movement direction, heading direction, speed, and locomotion style, are interactively specified and drive a kinematic character controller implemented using motion matching. Second, reinforcement learning is used to train a simulated character controller that is general enough to track the entire distribution of motion that can be generated by the kinematic controller. Our design emphasizes responsiveness to user input, visual quality, and low runtime cost for application in video-games.},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {206},
numpages = {11},
keywords = {reinforcement learning, real-time graphics, motion capture, physically based animation}
}

@misc{zhang2020vid2player,
      title={{Vid2Player}: Controllable Video Sprites that Behave and Appear like Professional Tennis Players}, 
      author={Haotian Zhang and Cristobal Sciutto and Maneesh Agrawala and Kayvon Fatahalian},
      year={2020},
      eprint={2008.04524},
      archivePrefix={arXiv},
      primaryClass={cs.GR}
}

@misc{aiinhollywood,
  author = {Edgar Alan Rayo},
  title = {Artificial Intelligence at {Disney}, {Viacom}, and Other Entertainment Giants},
  year = {2019},
  howpublished = {\url{https://emerj.com/ai-sector-overviews/ai-at-disney-viacom-and-other-entertainment-giants/}},
  note = {Accessed 2020-03-10}
}

@inproceedings{fakoor2013using,
  title={Using deep learning to enhance cancer diagnosis and classification},
  author={Fakoor, Rasool and Ladhak, Faisal and Nazi, Azade and Huber, Manfred},
  booktitle={Proceedings of the international conference on machine learning},
  volume={28},
  year={2013},
  organization={ACM, New York, USA}
}

@misc{pierson2017deep,
      title={Deep Learning in Robotics: A Review of Recent Research}, 
      author={Harry A. Pierson and Michael S. Gashler},
      year={2017},
      eprint={1707.07217},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@article{Lee_2020,
   title={Learning quadrupedal locomotion over challenging terrain},
   volume={5},
   ISSN={2470-9476},
   url={http://dx.doi.org/10.1126/scirobotics.abc5986},
   DOI={10.1126/scirobotics.abc5986},
   number={47},
   journal={Science Robotics},
   publisher={American Association for the Advancement of Science (AAAS)},
   author={Lee, Joonho and Hwangbo, Jemin and Wellhausen, Lorenz and Koltun, Vladlen and Hutter, Marco},
   year={2020},
   month={Oct},
   pages={eabc5986}
}

@article{BreastCancerAISystem,
author = {McKinney, Scott and Sieniek, Marcin and Godbole, Varun and Godwin, Jonathan and Antropova, Natasha and Ashrafian, Hutan and Back, Trevor and Chesus, Mary and Corrado, Greg and Darzi, Ara and Etemadi, Mozziyar and Garcia-Vicente, Florencia and Gilbert, Fiona and Halling-Brown, Mark and Hassabis, Demis and Jansen, Sunny and Karthikesalingam, Alan and Kelly, Christopher and King, Dominic and Shetty, Shravya},
year = {2020},
month = {01},
pages = {89-94},
title = {International evaluation of an {AI} system for breast cancer screening},
volume = {577},
journal = {Nature},
doi = {10.1038/s41586-019-1799-6}
}

@misc{openai2019dota,
      title={{Dota} 2 with Large Scale Deep Reinforcement Learning}, 
      author={OpenAI and : and Christopher Berner and Greg Brockman and Brooke Chan and Vicki Cheung and Przemyslaw Debiak and Christy Dennison and David Farhi and Quirin Fischer and Shariq Hashme and Chris Hesse and Rafal Józefowicz and Scott Gray and Catherine Olsson and Jakub Pachocki and Michael Petrov and Henrique P. d. O. Pinto and Jonathan Raiman and Tim Salimans and Jeremy Schlatter and Jonas Schneider and Szymon Sidor and Ilya Sutskever and Jie Tang and Filip Wolski and Susan Zhang},
      year={2019},
      eprint={1912.06680},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{alphastar,
author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech and Mathieu, Michaël and Dudzik, Andrew and Chung, Junyoung and Choi, David and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John and Jaderberg, Max and Silver, David},
year = {2019},
month = {11},
pages = {},
title = {Grandmaster level in {StarCraft} {II} using multi-agent reinforcement learning},
volume = {575},
journal = {Nature},
doi = {10.1038/s41586-019-1724-z}
}