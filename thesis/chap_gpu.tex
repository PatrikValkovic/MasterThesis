\chapter{GPU Programming}

Increase of processors performance has been for a long time driven by Moore's law -- \enquote{The complexity for minimum component costs has increased at a rate of roughly a factor of two per year. Certainly over the short term this rate can be expected to continue, if not to increase. Over the longer term, the rate of increase is a bit more uncertain, although there is no reason to believe it will not remain constant for at least 10 years} \citep{MooresLaw}. This \enquote{law}, if we may call it that way, is unfortunately limited by physical properties of components used within modern processors. These limits are both on the side of possible processing speed, and on the side of size and number of transistors in the processor core. Over the last years, scientists are predicting end of Moore's law \citep{MooresLawEnd}, and their voices are louder, since the size of transistors in the \acrfull{acc:cpu} reached $7nm$ in 2018 \citep{SamsungSevenNm}. 

Processors manufactures are well aware of the physical complications arising from the small size of the transistors, and invest more effort into multi--core processors. These processors have a number of independent cores, that can be utilized in parallel and can possibly increase the performance of the processor linearly in respect to the number of cores. To name a few, last server processors by Intel\textsuperscript{\textregistered} Xeon\textsuperscript{\textregistered} Platinum 8380 Processor with 40 cores and 80 threads \citep{IntelXeonPlatinum}, as well as AMD EPYC\texttrademark\ 7763 with 64 cores and 128 threads \citep{AMDEpyc}, are great example.

\acrfullpl{acc:gpu} takes this idea of multi--cores processors further. Rather than increasing single--thread performance, the \acrshort{acc:gpu} manufactures are focusing on massive parallelism using a great number of cores working in highly parallel and distributed manner \citep{GPUComputingOwens}. Using this approach, the \acrshort{acc:gpu} programming offer promising performance. Common consumer \acrshortpl{acc:gpu} can easily outperform current high--end \acrshortpl{acc:cpu} in the instruction throughput and memory bandwidth. These demands originally came from the game industry, which place great emphasis on parallel processing and reasonably real--time latency. 

Decision about the architecture however influence the way \acrshort{acc:gpu} are programmed. Unlike \acrshort{acc:cpu}, which is can run generic code, \acrshort{acc:gpu} is suited for specific kind of algorithms, that can fully use the underlying hardware. The program needs to have following mandatory properties to make it possible to run on \acrshort{acc:gpu} \citep{GPUComputingOwens}:
\begin{itemize}
    \item \textit{Large computation demands} -- \acrshort{acc:gpu} can deliver enormous performance, but has weak performance for short tasks without a lot of data. The overhead of allocating memory on \acrshort{acc:gpu} and moving it between can easily outweigh the advantage of using it. On the other hand, the real--time rendering require hundreds of operations per pixel, and \acrshort{acc:gpu} can easily meet these demands.
    \item \textit{Significant parallelism} -- the algorithm needs to be easy to parallelize and ideally scale to as many cores as possible. Whereas \acrshort{acc:cpu} provides tens of cores (up to 64 today), the \acrshort{acc:gpu} have hundreds or thousands of them (current cutting-edge \acrshort{acc:gpu} designed especially for \acrshort{acc:ai}, NVIDIA V100, has 5120 CUDA cores \citep{nvidiav100spec}), although with smaller per--core performance. If can algorithm utilize only a few of them, it may be slower than on multi--core \acrshort{acc:cpu}. Once again, real--time rendering can render each pixel independently, which makes it perfect candidate for \acrshort{acc:gpu} computing.
    \item \textit{Throughput over latency} -- because the \acrshort{acc:gpu} is highly parallel, the throughput is more important than the absolute latency of individual operations. From the point of rendering, human eye can perceive pictures in order of milliseconds. Operations in modern processors take in order of nanoseconds. Therefore, the absolute time to render a single pixel is not important as long as all the pixels are rendered in the same order of time. The algorithms cannot make assumptions about the running time of individual parts, but rather on the running time of the task as a whole.
\end{itemize}

\acrlong{acc:ea} fits well into these categories, as the individuals' fitness evaluation may be processed in parallel and independently. The crossover and mutation operators may be parallelized as well, as they operate and individuals or small set of individuals. We may parallelize the algorithm even more by processing each gene separately, as presented by \citet{CHENG2019514}.


%%%%%%%%%%%%%%%
%%           %%
%%  HISTORY  %%
%%           %%
%%%%%%%%%%%%%%%
\section{History}

Historically, \acrshort{acc:gpu} come from needs of game industry for real--time rendering. In the rendering process, a list of geometric primitives, usually triangle, are processed through number of stages to form a final picture. The primitives can be processed independently and therefore in parallel, which makes real--time rendering the ideal case for use of \acrshort{acc:gpu}. The typical operations in graphics consists of \citep{GPUComputingOwens}\index{rendering pipeline}:
\begin{itemize}
    \item Vertex stage, that transforms and compute properties per vertex. Typical operations are transformation of the geometric primitives from world space (that is the coordinates in the scene) into screen space (that is the coordinates in respect to the viewer point of view) and computing additional vertex properties like texture coordinates.
    \item Primitive assembly, that transform geometric primitives into triangles -- the standard geometric primitive for \acrshort{acc:gpu} to understand. This stage may also clip the primitives, that are not in the view of the observer and save some computation in the following stages.
    \item Rasterization takes generated triangles and determine, which pixels correspond to provided triangle. These pixels do not necessary need match number of pixels of the screen and are usually referred as fragments (for example superscaling technique renders picture in higher resolution and then downsample the final picture to match screen resolution \citep{GameGraphicProgramming}). Each triangle may be composed by hundreds or thousands of fragments. Moreover, the rasterization typically interpolate vertex properties between the fragments.
    \item Fragment stage process each fragment and typically determine the final color of the fragment. It may compute fragment interactions with the lights in the scene, fetch colors from textures and so on. This stage is usually most demanding, as typical scene consists of millions of fragments.
    \item Composition stage assembles all the fragments into a final image. It may among other test fragments visibility and their blending.
\end{itemize}

The stages \acrshort{acc:gpu} performs is usually referred as \emph{rendering pipeline} and may slightly differ. At the beginning, stages mentioned above have been preprogrammed by the manufacture and developers have only a limited options how to influence the stages of the pipeline (also known as the fixed--function pipeline). As the software complexity increased, the need for more control arise and the manufactures provided way to program the individual stages of the pipeline. These programs are called \emph{shaders} and their capabilities improved over the years. In 2006, Microsoft introduce Shading Model 4.0, which allowed using same programming interface and hardware both for vertex and fragment shader \citep{DirectX10}. Not only that, but more stages emerged (like tessellation and geometry shaders) to allow developers more control. Today, two major \acrfull{acc:api} exists -- proprietary  DirectX and open--source OpenGL. Note that some operations of the rendering pipeline, such as primitive assembly, rasterization, and composition are still implemented by the \acrshort{acc:gpu} manufactures and in most cases are implemented by special--purpose hardware components \citep{SoftwareRasterization}. They are therefore integral part of the rendering pipeline and are not possible to modify.

Soon, scientists and engineers identified many more problems suitable for processing on \acrshort{acc:gpu}. Although some parts of the rendering pipeline were fully programmable, the pipeline still inherently graphical and some stages are not possible to skip. To run general--purpose programs on \acrshort{acc:gpu} required encoding the problem in the domain of geometric primitives and use available programmable and special--purpose hardware to implement the algorithm. Moreover, the programmers need to decide which part of the hardware will execute which part of the calculation and how the pipeline's fixed stages will affect the data structure. As shader programs do not have access to shared memory, the data passing were realized using textures, vertices, and fragment properties \citep{GPUComputingOwens}. These complications discouraged general use of \acrshort{acc:gpu} for general--purpose programs, although some efforts have been made to hide underlying rendering pipeline from the programmer point of view \citep{BrookGPU}.

Lack of support for general--purpose program on \acrshort{acc:gpu} inspired companies to develop new approach, that would give programmers better control over the underlying hardware. In 2007, NVIDIA introduced first version of \acrfull{acc:cuda} \citep{CUDAwiki}. Open source implementation of general--purpose programming came in 2008 as Open Computing Language (OpenCL) by Khronos Group \citep{OpenCLRelease}. These are higher level interfaces with C--like syntax exposing \acrshort{acc:gpu} resources without any connection to the graphical pipeline. Programmer is given control of execution and parallelization of the program, as well as memory access. Over the years, these technologies undergo a number of improvements (current version is CUDA 11.2, respectively OpenCL 3.0) adding support for data types, language constructs and hardware.

CUDA become de facto standard in the field of general--purpose computing on \acrshort{acc:gpu} and I will focus primarily on it. Fortunately, other technologies like OpenCL have similar underlying architecture and approach to the \acrshort{acc:gpu} programming. Following section should therefore generalize for them as well.




%%%%%%%%%%%%%%%%%%%%
%%                %%
%%  ARCHITECTURE  %%
%%                %%
%%%%%%%%%%%%%%%%%%%%
\section{Architecture}




%%%%%%%%%%%%%%%
%%           %%
%%  PYTORCH  %%
%%           %%
%%%%%%%%%%%%%%%
\section{PyTorch}




%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                       %%
%%  EVA PARALLELIZATION  %%
%%                       %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Evolutionary Algorithms parallelization}
