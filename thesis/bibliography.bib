%
%  An example of a bibliographical database for bibTeX
%
%  Recommended software for maintenance of *.bib files:
%    JabRef, http://jabref.sourceforge.net/
%
%  BEWARE:
%
%    *  If a name contains a capital letter, which must be kept such,
%       use curly brackets ({T}hailand, {HIV}).
%
%  ===========================================================================

@article{cantu1998survey,
  title={A survey of parallel genetic algorithms},
  author={Cant{\'u}-Paz, Erick},
  journal={Calculateurs paralleles, reseaux et systems repartis},
  volume={10},
  number={2},
  pages={141--171},
  year={1998},
  publisher={Citeseer}
}

@book{HowToSolveItModernHeuristics,
  title={How to solve it: modern heuristics},
  author={Michalewicz, Zbigniew and Fogel, David B},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@inproceedings{veronese2010differential,
  title={Differential evolution algorithm on the {GPU} with {C-CUDA}},
  author={Veronese, Lucas de P and Krohling, Renato A},
  booktitle={IEEE Congress on Evolutionary Computation},
  pages={1--7},
  year={2010},
  organization={IEEE}
}

@article{circuitdesignoptimizationea,
author = {Barari, Mansour and Karimi, Hamid Reza and Razaghian, Farhad},
year = {2014},
month = {04},
pages = {1-12},
title = {Analog Circuit Design Optimization Based on Evolutionary Algorithms},
volume = {2014},
journal = {Mathematical Problems in Engineering},
doi = {10.1155/2014/593684}
}

@article{CHENG2019514,
title = {Accelerating genetic algorithms with {GPU} computing: A selective overview},
journal = {Computers \& Industrial Engineering},
volume = {128},
pages = {514-525},
year = {2019},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2018.12.067},
url = {https://www.sciencedirect.com/science/article/pii/S036083521830665X},
author = {John Runwei Cheng and Mitsuo Gen},
keywords = {Parallel genetic algorithms, GPU computing, Parallelism},
abstract = {The emergence of GPU-CPU heterogeneous architectures has led to a fundamental paradigm shift in parallel programming. Accelerating Genetic Algorithms (GAs) on these architectures has received significant attention from both practitioners and researchers ever since GPUs emerged. In the past decade we have witnessed many progresses on migrating parallel GAs from CPU to GPU (Graphical Processing Unit) architecture, which makes this research field truly enter into the world of High Performance Computing (HPC), and demonstrates a great potential to many research disciplines and industrial worlds that can benefit from the power of GPU accelerated stochastic global search to explore large and complex search spaces for better solutions. Designing a parallel algorithm on GPU is quite different from designing one on CPU. On CPU architecture, we typically consider how to distribute data across tens of CPU threads, while on GPU architecture, we have more than hundreds of thousands of GPU threads running simultaneously. Therefore, we should rethink the design approaches and implementation strategies of parallel algorithms to fully utilize the computing power of GPUs to accelerate the computation of GAs. The intention of this paper is to give an overview on selective works of parallel GAs designed for GPU architecture. In this survey paper, we first reexamine the concept of granularity of parallelism for GAs on GPU architecture, discuss how the aspect of data layout affect the kernel design to maximize memory bandwidth, and explain how to organize threads in grid and blocks to expose sufficient parallelism to GPU. The comprehensive overview on selective works since 2010 then follows. The focus is mainly on the perspective of GPU architecture: how to accelerate GAs with GPU computing. Performance issues are not touched in this review, because most of these works are conducted on very early GPU cards, which are out of date already. We finally discuss some future research suggestions in the last section, especially about how to build up an efficient implementation of parallel GAs for hyper-scale computing. Many industrial and academic disciplines will be benefited from the GPU accelerated parallel GAs, one of the promising area is to evolve better deep neural networks.}
}

@book{darwin1964origin,
  title={On the origin of species: A facsimile of the first edition},
  author={Darwin, Charles},
  volume={11},
  year={1964},
  publisher={Harvard University Press}
}

@article{SelfAdaptiveFeaturesInRealParameterEvolutionaryAlgorithms,
  author  = {H. -. {Beyer} and K. {Deb}},
  journal = {IEEE Transactions on Evolutionary Computation},
  title   = {On self-adaptive features in real-parameter evolutionary algorithms},
  year    = {2001},
  volume  = {5},
  number  = {3},
  pages   = {250-270},
  doi     = {10.1109/4235.930314}
}

@misc{TSPArticle,
  title = {Sales and Chips},
  author = {Malkevitch, Joe},
  year = {2005},
  month = {09},
  howpublished = {\url{http://www.ams.org/publicoutreach/feature-column/fcarc-tsp}},
  note = {Accessed: 2010-09-30}
}

@article{ExplorationExploitationDilemaRL,
author = {Yogeswaran, Mohan and S.G., Ponnambalam},
year = {2012},
month = {09},
pages = {},
title = {Reinforcement learning: Exploration-exploitation dilemma in multi-agent foraging task},
volume = {49},
journal = {OPSEARCH},
doi = {10.1007/s12597-012-0077-2}
}

@book{IntroductionToEA,
  title={Introduction to evolutionary algorithms},
  author={Yu, Xinjie and Gen, Mitsuo},
  year={2010},
  publisher={Springer Science \& Business Media}
}

@article{HollandGA,
  title={Adaptation in natural and artificial systems, University of Michigan press},
  author={Holland, John H.},
  journal={Ann arbor, MI},
  volume={1},
  number={97},
  pages={5},
  year={1975}
}

@incollection{IntroToGA,
  title={Genetic algorithms},
  author={Sivanandam, SN and Deepa, SN},
  booktitle={Introduction to genetic algorithms},
  pages={15--37},
  year={2008},
  publisher={Springer}
}

@inproceedings{razali2011genetic,
  title={Genetic algorithm performance with different selection strategies in solving TSP},
  author={Razali, Noraini Mohd and Geraghty, John and others},
  booktitle={Proceedings of the world congress on engineering},
  volume={2},
  pages={1--6},
  year={2011},
  organization={International Association of Engineers Hong Kong}
}

@incollection{simulatedannealing,
  title={Simulated annealing},
  author={Van Laarhoven, Peter JM and Aarts, Emile HL},
  booktitle={Simulated annealing: Theory and applications},
  pages={7--15},
  year={1987},
  publisher={Springer}
}

@article{WVDF,
title = {Selection weighted vector directional filters},
journal = {Computer Vision and Image Understanding},
volume = {94},
number = {1},
pages = {140-167},
year = {2004},
note = {Special Issue: Colour for Image Indexing and Retrieval},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2003.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S107731420300198X},
author = {Rastislav Lukac and Bogdan Smolka and Konstantinos N Plataniotis and Anastasios N Venetsanopoulos},
keywords = {Multichannel image processing, Impulsive noise, Directional processing of color images, Order-statistic theory, Weighted median filters, Optimization},
abstract = {In this paper, a class of weighted vector directional filters (WVDFs) based on the selection of the output sample from the multichannel input set is analyzed and optimized. The WVDF output minimizes the sum of weighted angular distances to other input samples from the filtering window. Dependent on the weighting coefficients, the class of the WVDFs can be designed to perform a number of smoothing operations with different properties, which can be applied for specific filtering scenarios. In order to adapt the weighting coefficients to varying noise and image statistics, we introduce a methodology, which achieves an optimal trade-off between smoothing and detail preserving characteristics. The proposed angular optimization algorithms take advantage of adaptive stack filters design and weighted median filtering framework. The optimized WVDFs are able to remove image noise, while maintaining excellent signal-detail preservation capabilities and sufficient robustness for a variety of signal and noise statistics.}
}


@book{GeneticAlgorithmEssentials,
author = {Kramer, Oliver},
year = {2017},
month = {01},
pages = {},
title = {Genetic Algorithm Essentials},
isbn = {978-3-319-52155-8},
doi = {10.1007/978-3-319-52156-5},
publisher      = {Springer},
}

@incollection{ES-original,
  title={Evolutionsstrategien},
  author={Rechenberg, Ingo},
  booktitle={Simulationsmethoden in der Medizin und Biologie},
  pages={83--114},
  year={1978},
  publisher={Springer}
}

@article{EScomprehensiveintroduction,
author = {Beyer, Hans-Georg and Schwefel, Hans-Paul},
year = {2002},
month = {03},
pages = {3-52},
title = {Evolution strategies - A comprehensive introduction},
volume = {1},
journal = {Natural Computing},
doi = {10.1023/A:1015059928466}
}

@book{HandbookOfMetaheuristics,
author = {Gendreau, Michel and Potvin, Jean-Yves},
year = {2010},
month = {01},
pages = {},
title = {Handbook of Metaheuristics},
volume = {146},
isbn = {978-1-4419-1663-1},
journal = {International Series in Operations Research & Management Science},
doi = {10.1007/978-1-4419-1665-5},
publisher      = {Springer},
}

@inproceedings{SteadyStateEvolutionStrategy,
author = {Wakunda, J\"{u}rgen and Zell, Andreas},
title = {A New Selection Scheme for Steady-State Evolution Strategies},
year = {2000},
isbn = {1558607080},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
abstract = {In this paper, a new selection scheme for (μ + 1) a steady-state evolution strategy is described: the so-called median selection. In contrast to generational algorithms, only one individual is generated and evaluated in one step of the algorithm and is immediately integrated into the population. Previous steady-state algorithms are similar to the (μ + λ) selection scheme in evolution strategies, which has a disadvantage in the fast self-adaptation of mutation step-length. This is compensated by the presented median selection, which is oriented at the (μ, λ) selection. The median selection is compared with other steady-state selection schemes and with (μ, λ) selection. As a result, median selection achieves better or equally good results as the other selection schemes for a large number of benchmark functions. Additionally, it is shown that the use of a sequential steady-state evolution strategy is advantageous even on one-processor computers.},
booktitle = {Proceedings of the 2nd Annual Conference on Genetic and Evolutionary Computation},
pages = {794–801},
numpages = {8},
location = {Las Vegas, Nevada},
series = {GECCO'00}
}

@incollection{BlendCrossoverOriginal,
  title={Real-coded genetic algorithms and interval-schemata},
  author={Eshelman, Larry J and Schaffer, J David},
  booktitle={Foundations of genetic algorithms},
  volume={2},
  pages={187--202},
  year={1993},
  publisher={Elsevier}
}

@article{CauchyDistributionMutation,
  author  = {Yao, Xin and Liu, Yong and Lin, Guangming},
  journal = {IEEE Transactions on Evolutionary Computation},
  title   = {Evolutionary programming made faster},
  year    = {1999},
  volume  = {3},
  number  = {2},
  pages   = {82-102},
  doi     = {10.1109/4235.771163}
}

@article{DecayGA,
  author  = {Jiang, Yi and Zhang, Fan},
  year    = {2020},
  month   = {08},
  pages   = {012054},
  title   = {Study on BP Neural Network Optimization by Improved Decay Parameter Genetic Algorithm},
  volume  = {1621},
  journal = {Journal of Physics: Conference Series},
  doi     = {10.1088/1742-6596/1621/1/012054}
}

@inproceedings{onefifthrule,
  TITLE = {Benchmarking the (1+1) Evolution Strategy with One-Fifth Success Rule on the {BBOB}-2009 Function Testbed},
  AUTHOR = {Auger, Anne},
  URL = {https://hal.inria.fr/inria-00430515},
  BOOKTITLE = {{ACM-GECCO Genetic and Evolutionary Computation Conference}},
  ADDRESS = {Montreal, Canada},
  YEAR = {2009},
  MONTH = Jul,
  PDF = {https://hal.inria.fr/inria-00430515/file/wk2037-auger.pdf},
  HAL_ID = {inria-00430515},
  HAL_VERSION = {v1},
}

@article{onefifthruleoriginal,
author = {Schumer, MA and Steiglitz, Kenneth},
year = {1968},
month = {07},
pages = {270 - 276},
title = {Adaptive step size random search},
volume = {AC13},
journal = {Automatic Control, IEEE Transactions on},
doi = {10.1109/TAC.1968.1098903}
}

@article{differentialevolutionoriginal,
  author  = {Storn, Rainer and Price, Kenneth},
  year    = {1997},
  month   = {01},
  pages   = {341-359},
  title   = {Differential Evolution - A Simple and Efficient Heuristic for Global Optimization over Continuous Spaces},
  volume  = {11},
  journal = {Journal of Global Optimization},
  doi     = {10.1023/A:1008202821328}
}

@inproceedings{PSOOriginal,
  author    = {J. {Kennedy} and R. {Eberhart}},
  booktitle = {Proceedings of ICNN'95 - International Conference on Neural Networks},
  title     = {Particle swarm optimization},
  year      = {1995},
  volume    = {4},
  number    = {},
  pages     = {1942-1948 vol.4},
  doi       = {10.1109/ICNN.1995.488968}
}

@unpublished{SPSO,
  title       = {{Standard Particle Swarm Optimisation}},
  author      = {Clerc, Maurice},
  url         = {https://hal.archives-ouvertes.fr/hal-00764996},
  note        = {15 pages},
  year        = {2012},
  month       = Sep,
  keywords    = {particle swarm ; optimisation},
  pdf         = {https://hal.archives-ouvertes.fr/hal-00764996/file/SPSO_descriptions.pdf},
  hal_id      = {hal-00764996},
  hal_version = {v1}
}

@article{PSOtopologies,
  author  = {Xu, Yue and Pi, Dechang},
  year    = {2020},
  month   = {07},
  pages   = {},
  title   = {A reinforcement learning-based communication topology in particle swarm optimization},
  volume  = {32},
  journal = {Neural Computing and Applications},
  doi     = {10.1007/s00521-019-04527-9}
}

@inproceedings{SPSObenchmark,
  author    = {M. {Zambrano-Bigiarini} and M. {Clerc} and R. {Rojas}},
  booktitle = {2013 {IEEE} Congress on Evolutionary Computation},
  title     = {Standard Particle Swarm Optimisation 2011 at {CEC}-2013: A baseline for future {PSO} improvements},
  year      = {2013},
  month     = {06},
  volume    = {},
  number    = {},
  pages     = {2337-2344},
  journal   = {2013 IEEE Congress on Evolutionary Computation, CEC 2013},
  doi       = {10.1109/CEC.2013.6557848}
}

@article{PSOvelocitylimit,
author = {Bonyadi, Mohammad reza and Michalewicz, Zbigniew and Li, Xiaodong},
year = {2014},
month = {04},
pages = {},
title = {An analysis of the velocity updating rule of the particle swarm optimization algorithm},
volume = {20},
journal = {Journal of Heuristics},
doi = {10.1007/s10732-014-9245-2}
}

@inproceedings{psobiasinzero,
  author    = {Monson, Christopher K. and Seppi, Kevin D.},
  title     = {Exposing Origin-Seeking Bias in PSO},
  year      = {2005},
  isbn      = {1595930108},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1068009.1068045},
  doi       = {10.1145/1068009.1068045},
  abstract  = {We discuss testing methods for exposing origin-seeking bias in PSO motion algorithms. The strategy of resizing the initialization space, proposed by Gehlhaar and Fogel and made popular in the PSO context by Angeline, is shown to be insufficiently general for revealing an algorithm's tendency to focus its efforts on regions at or near the origin. An alternative testing method is proposed that reveals problems with PSO motion algorithms that are not visible when merely resizing the initialization space.},
  booktitle = {Proceedings of the 7th Annual Conference on Genetic and Evolutionary Computation},
  pages     = {241–248},
  numpages  = {8},
  keywords  = {optimization, swarm intelligence, initialization bias},
  location  = {Washington DC, USA},
  series    = {GECCO '05}
}

@article{MooresLaw,
  author  = {R. R. {Schaller}},
  journal = {IEEE Spectrum},
  title   = {Moore's law: past, present and future},
  year    = {1997},
  volume  = {34},
  number  = {6},
  pages   = {52-59},
  doi     = {10.1109/6.591665}
}

@misc{MooresLawEnd,
  title = {{M}oore’s Law Dead by 2022, Expert Says},
  author = {Merritt, Rick},
  year = {2013},
  month = {08},
  howpublished = {\url{https://www.citationmachine.net/bibliographies/d5c984d9-c825-4753-892c-de9e99cc8fac}},
  note = {Accessed: 2021-04-12}
}

@misc{SamsungSevenNm,
  title = {{S}amsung {E}lectronics Starts Production of {EUV}-based 7nm {LPP} Process},
  year = {2018},
  month = {10},
  howpublished = {\url{https://news.samsung.com/global/samsung-electronics-starts-production-of-euv-based-7nm-lpp-process}},
  note = {Accessed: 2021-04-12},
  author = {SAMSUNG},
}

@misc{IntelXeonPlatinum,
  title = {{I}ntel\textsuperscript{\textregistered} {X}eon\textsuperscript{\textregistered} {P}latinum 8380 Processor Specification ({60M} Cache, {2.30 GHz})},
  howpublished = {\url{https://www.intel.com/content/www/us/en/products/sku/212287/intel-xeon-platinum-8380-processor-60m-cache-2-30-ghz/specifications.html}},
  note = {Accessed: 2021-04-12},
  author = {{Intel Coporation}},
  year={2021},
}


@misc{AMDEpyc,
  title = {{AMD} {EPYC}\texttrademark\ 7763 Specification},
  howpublished = {\url{https://www.amd.com/en/products/cpu/amd-epyc-7763}},
  note = {Accessed: 2021-04-12},
  author={{Advanced Micro Devices, Inc}},
  year={2021},
  month={03},
}

@article{GPUComputingOwens,
  author  = {Owens, John and Houston, Mike and Luebke, David and Green, Simon and Stone, John and Phillips, James},
  year    = {2008},
  month   = {05},
  pages   = {879-899},
  title   = {GPU computing},
  volume  = {96},
  journal = {Proceedings of the IEEE},
  doi     = {10.1109/JPROC.2008.917757}
}

@misc{nvidiav100spec,
  title = {{NVIDIA} {V100} Specification},
  howpublished = {\url{https://www.nvidia.com/en-gb/data-center/v100/}},
  note = {Accessed: 2021-04-12},
  author={{NVIDIA Corporation}},
  year={2020},
}

@book{GameGraphicProgramming,
  title={Game Graphic Programming},
  author={Sherrod, A.},
  isbn={9781584506157},
  lccn={2007935957},
  series={Course Technology PTR game development series},
  url={https://books.google.cz/books?id=gasLAAAAQBAJ},
  year={2008},
  publisher={Course Technology/Charles River Media/Cengage Learning}
}

@article{DirectX10,
author = {Blythe, David},
title = {The Direct3D 10 System},
year = {2006},
issue_date = {July 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/1141911.1141947},
doi = {10.1145/1141911.1141947},
abstract = {We present a system architecture for the 4th generation of PC-class programmable graphics processing units (GPUs). The new pipeline features significant additions and changes to the prior generation pipeline including a new programmable stage capable of generating additional primitives and streaming primitive data to memory, an expanded, common feature set for all of the programmable stages, generalizations to vertex and image memory resources, and new storage formats. We also describe structural modifications to the API, runtime, and shading language to complement the new pipeline. We motivate the design with descriptions of frequently encountered obstacles in current systems. Throughout the paper we present rationale behind prominent design choices and alternatives that were ultimately rejected, drawing on insights collected during a multi-year collaboration with application developers and hardware designers.},
journal = {ACM Trans. Graph.},
month = jul,
pages = {724–734},
numpages = {11},
keywords = {programmable graphics hardware, programmable shading, graphics systems}
}

@inproceedings{SoftwareRasterization,
author = {Laine, Samuli and Karras, Tero},
title = {High-Performance Software Rasterization on GPUs},
year = {2011},
isbn = {9781450308960},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2018323.2018337},
doi = {10.1145/2018323.2018337},
abstract = {In this paper, we implement an efficient, completely software-based graphics pipeline on a GPU. Unlike previous approaches, we obey ordering constraints imposed by current graphics APIs, guarantee hole-free rasterization, and support multisample antialiasing. Our goal is to examine the performance implications of not exploiting the fixed-function graphics pipeline, and to discern which additional hardware support would benefit software-based graphics the most.We present significant improvements over previous work in terms of scalability, performance, and capabilities. Our pipeline is malleable and easy to extend, and we demonstrate that in a wide variety of test cases its performance is within a factor of 2--8x compared to the hardware graphics pipeline on a top of the line GPU.Our implementation is open sourced and available at http://code.google.com/p/cudaraster/},
booktitle = {Proceedings of the ACM SIGGRAPH Symposium on High Performance Graphics},
pages = {79–88},
numpages = {10},
location = {Vancouver, British Columbia, Canada},
series = {HPG '11}
}

@article{BrookGPU,
author = {Buck, Ian and Foley, Tim and Horn, Daniel and Sugerman, Jeremy and Fatahalian, Kayvon and Houston, Mike and Hanrahan, Pat},
title = {Brook for {GPU}s: Stream Computing on Graphics Hardware},
year = {2004},
issue_date = {August 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/1015706.1015800},
doi = {10.1145/1015706.1015800},
abstract = {In this paper, we present Brook for GPUs, a system for general-purpose computation on programmable graphics hardware. Brook extends C to include simple data-parallel constructs, enabling the use of the GPU as a streaming co-processor. We present a compiler and runtime system that abstracts and virtualizes many aspects of graphics hardware. In addition, we present an analysis of the effectiveness of the GPU as a compute engine compared to the CPU, to determine when the GPU can outperform the CPU for a particular algorithm. We evaluate our system with five applications, the SAXPY and SGEMV BLAS operators, image segmentation, FFT, and ray tracing. For these applications, we demonstrate that our Brook implementations perform comparably to hand-written GPU code and up to seven times faster than their CPU counterparts.},
journal = {ACM Trans. Graph.},
month = aug,
pages = {777–786},
numpages = {10},
keywords = {GPU Computing, Stream Computing, Brook, Programmable Graphics Hardware, Data Parallel Computing}
}

@misc{CUDAwiki,
author = "{Wikipedia contributors}",
title = "CUDA --- {Wikipedia}{,} The Free Encyclopedia",
year = "2021",
howpublished = "\url{https://en.wikipedia.org/w/index.php?title=CUDA&oldid=1017440526}",
  note = {Accessed: 2021-04-12},
}

@misc{ OpenCLRelease,
author = {{The Khronos\texttrademark\ Group}},
title = {The {K}hronos {G}roup Releases {OpenCL }1.0 Specification},
year = {2008},
month        = {12},
howpublished = "\url{https://khr.io/e9}",
  note = {Accessed: 2021-04-12},
}

@book{CUDAguide,
title = {{CUDA} {C++} Programming Guide},
year = {2021},
publisher = {NVIDIA Corporation},
address = {San Francisco, CA, USA},
edition = {PG-02829-001\_v11.2}
}

@misc{NVIDIAhistory,
author = {Sanglard, Fabien},
title = {A History of {NVIDIA} Stream Multiprocessor},
year = {2020},
month        = {05},
howpublished = {\url{https://fabiensanglard.net/cuda/}},
  note = {Accessed: 2021-04-12},
}

@INPROCEEDINGS{MatrixMultiplicationGPU,  
author={X. {Cui} and Y. {Chen} and H. {Mei}},  
booktitle={2009 15th International Conference on Parallel and Distributed Systems},   
title={Improving Performance of Matrix Multiplication and FFT on GPU},   
year={2009},  
volume={},  
number={}, 
 pages={42-48},  
 doi={10.1109/ICPADS.2009.8}
}

@article{GPUMatrixMultiplication,
author = {Hazra, Tapan and Ray, Utpal},
year = {2016},
month = {11},
pages = {98-105},
title = {Matrix Multiplication using Strassen’s Algorithm on CPU \& GPU},
volume = {4},
journal = {INTERNATIONAL JOURNAL OF COMPUTER SCIENCES AND ENGINEERING}
}

@article{harris2007optimizing,
  title={Optimizing parallel reduction in {CUDA}},
  author={Harris, Mark and others},
  journal={Nvidia developer technology},
  volume={2},
  number={4},
  pages={1--39},
  year={2007},
  publisher={NVIDIA Corp. California}
}

@InProceedings{GPUsorting,
author="Peters, Hagen
and Schulz-Hildebrandt, Ole
and Luttenberger, Norbert",
editor="Wyrzykowski, Roman
and Dongarra, Jack
and Karczewski, Konrad
and Wasniewski, Jerzy",
title="Fast In-Place Sorting with CUDA Based on Bitonic Sort",
booktitle="Parallel Processing and Applied Mathematics",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="403--410",
abstract="State of the art graphics processors provide high processing power and furthermore, the high programmability of GPUs offered by frameworks like CUDA increases their usability as high-performance co-processors for general-purpose computing. Sorting is well-investigated in Computer Science in general, but (because of this new field of application for GPUs) there is a demand for high-performance parallel sorting algorithms that fit to the characteristics of modern GPU-architecture.",
isbn="978-3-642-14390-8"
}

@misc{ StackOverflowSurvey,
author = {{Stack Exchange Inc}},
title = {Stack Overflow Developer Survey 2020},
year = {2020},
howpublished = {\url{https://insights.stackoverflow.com/survey/2020}},
  note = {Accessed: 2021-04-14},
}

@misc{ PyTorchDoc,
author = {{PyTorch}},
title = {{PyTorch} Documentation},
year = {2019},
howpublished = {\url{https://pytorch.org/docs/stable/index.html}},
  note = {Accessed: 2021-04-14},
}

@article{PGAPack,
author = {Levine, David},
year = {1996},
month = {03},
pages = {},
title = {Users Guide to the PGAPack Parallel Genetic Algorithm Library},
doi = {10.2172/366458}
}
