%
%  An example of a bibliographical database for bibTeX
%
%  Recommended software for maintenance of *.bib files:
%    JabRef, http://jabref.sourceforge.net/
%
%  BEWARE:
%
%    *  If a name contains a capital letter, which must be kept such,
%       use curly brackets ({T}hailand, {HIV}).
%
%  ===========================================================================

@article{cantu1998survey,
  title={A survey of parallel genetic algorithms},
  author={Cant{\'u}-Paz, Erick},
  journal={Calculateurs paralleles, reseaux et systems repartis},
  volume={10},
  number={2},
  pages={141--171},
  year={1998},
  publisher={Citeseer}
}

@book{michalewicz2013solve,
  title={How to solve it: modern heuristics},
  author={Michalewicz, Zbigniew and Fogel, David B},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@article{cheng2019accelerating,
  title={Accelerating genetic algorithms with GPU computing: A selective overview},
  author={Cheng, John Runwei and Gen, Mitsuo},
  journal={Computers \& Industrial Engineering},
  volume={128},
  pages={514--525},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{veronese2010differential,
  title={Differential evolution algorithm on the GPU with C-CUDA},
  author={Veronese, Lucas de P and Krohling, Renato A},
  booktitle={IEEE Congress on Evolutionary Computation},
  pages={1--7},
  year={2010},
  organization={IEEE}
}

@article{CIRESAN2012333,
title = {Multi-column deep neural network for traffic sign classification},
journal = {Neural Networks},
volume = {32},
pages = {333-338},
year = {2012},
note = {Selected Papers from IJCNN 2011},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2012.02.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608012000524},
author = {Dan Cireşan and Ueli Meier and Jonathan Masci and Jürgen Schmidhuber},
keywords = {Deep neural networks, Image classification, Traffic signs, Image preprocessing},
abstract = {We describe the approach that won the final phase of the German traffic sign recognition benchmark. Our method is the only one that achieved a better-than-human recognition rate of 99.46%. We use a fast, fully parameterizable GPU implementation of a Deep Neural Network (DNN) that does not require careful design of pre-wired feature extractors, which are rather learned in a supervised way. Combining various DNNs trained on differently preprocessed data into a Multi-Column DNN (MCDNN) further boosts recognition performance, making the system insensitive also to variations in contrast and illumination.}
}